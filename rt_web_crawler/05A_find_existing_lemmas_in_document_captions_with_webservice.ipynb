{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08adf2f7-e1aa-4a4a-8376-423da3c553fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import urllib.parse\n",
    "\n",
    "from datetime import date\n",
    "from pandas import DataFrame \n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6642ef2-1f8a-4826-b11d-673391e71cbc",
   "metadata": {},
   "source": [
    "## I. Using vabamorph analyser directly to extract lemmas from texts\n",
    "\n",
    "The most basic way to idex a document is to analyse it word by word:\n",
    "* This keeps all possible interpretation of the word in the outcome.\n",
    "* This creates many spurious analysis results (sadama --> sada, sadam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7adc6ddc-74ea-4063-9d27-661e3d50a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>wordform</th>\n",
       "      <th>lemma</th>\n",
       "      <th>sublemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Presidendi</td>\n",
       "      <td>president</td>\n",
       "      <td>[president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ametiraha</td>\n",
       "      <td>ametiraha</td>\n",
       "      <td>[ameti, raha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>seadus</td>\n",
       "      <td>seadu</td>\n",
       "      <td>[seadu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>seadus</td>\n",
       "      <td>seadus</td>\n",
       "      <td>[seadus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    wordform      lemma      sublemmas\n",
       "0      0  Presidendi  president    [president]\n",
       "1      1   ametiraha  ametiraha  [ameti, raha]\n",
       "2      2      seadus      seadu        [seadu]\n",
       "2      2      seadus     seadus       [seadus]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_document_caption(caption: str):\n",
    "    \"\"\"\n",
    "    Uses web service to extract words and sub-words form document captions\n",
    "\n",
    "    Returns a four column table with columns index, wordform, lemma, sublemmas.\n",
    "    There can be several rows for each word as each word is analysed separately.\n",
    "    All rows with the same index correspond to the same word.\n",
    "    Wordform columns is added to facilitate tokenisation debugging.\n",
    "    \"\"\"\n",
    "    ANALYZER_QUERY = \"https://smart-search.tartunlp.ai/api/analyser/process\"\n",
    "    HEADERS = {\"Content-Type\": \"application/json; charset=utf-8\"}\n",
    "    POST_DATA_TEMPLATE = {'params': {\"vmetajson\": [\"--guess\"]}, 'content': caption}\n",
    "\n",
    "    response = requests.post(ANALYZER_QUERY, json=POST_DATA_TEMPLATE, headers=HEADERS)\n",
    "    assert response.ok, \"Webservice failed\"\n",
    "    response = response.json()\n",
    "\n",
    "    token_count = len(response['annotations']['tokens'])\n",
    "    tbl = DataFrame({'wordform': [None] * token_count, 'lemma': [None] * token_count})\n",
    "    for i, token in enumerate(response['annotations']['tokens']):\n",
    "        features = token['features']\n",
    "        tbl.loc[i, 'wordform'] = features['token']\n",
    "        tbl.loc[i, 'lemma'] = list(set(map(lambda x: x['lemma'], features['mrf'])))\n",
    "\n",
    "    tbl =  tbl.reset_index().explode('lemma')\n",
    "    tbl['sublemmas'] = tbl['lemma'].str.split('_', regex=False)\n",
    "    tbl['lemma'] = tbl['lemma'].str.replace('_', '', regex=False)\n",
    "    return tbl\n",
    "\n",
    "# Example output\n",
    "analyze_document_caption('Presidendi ametiraha seadus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cd5d9-a573-41d0-8218-f6f1d2604b50",
   "metadata": {},
   "source": [
    "### Example analysis of all captions\n",
    "\n",
    "To buid a necessary input file to query normalisation service, we need to analyse all the document captions and get occurence counts for lemmas. In this analysis we ignore the fact that some wordforms have multiple lemmas and treat each row with the same weight.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9bdb19e3-b9f3-4a2f-bcf2-35d00a9546f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e565d13b11f4816b3ab619d1a1bf909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sources = read_csv('results/state_laws.csv', header=0)\n",
    "\n",
    "result = [None] *  len(sources)\n",
    "for i, caption in tqdm(enumerate(sources['document_title']), total=len(sources)):\n",
    "    result[i] = analyze_document_caption(caption).assign(doc_id = i)\n",
    "\n",
    "result = concat(result, axis=0)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad109171-3b9e-4dc1-b76c-d894d9a8ec8d",
   "metadata": {},
   "source": [
    "Now we can form a table of lemma counts and filter it to get rid of spurious tokens that are not lemmas\n",
    "or find out problems with preprocessing of document captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "759a4df5-d65c-4070-9700-49d499ac6a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence_count</th>\n",
       "      <th>document_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seadus</th>\n",
       "      <td>3004</td>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seadu</th>\n",
       "      <td>2988</td>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>1178</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vabariik</th>\n",
       "      <td>584</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratifitseerimine</th>\n",
       "      <td>472</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eesti</th>\n",
       "      <td>370</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eesti</th>\n",
       "      <td>363</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seadustik</th>\n",
       "      <td>274</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>konventsioon</th>\n",
       "      <td>243</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valitsus</th>\n",
       "      <td>229</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leping</th>\n",
       "      <td>225</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vaheline</th>\n",
       "      <td>223</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euroopa</th>\n",
       "      <td>220</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euroopa</th>\n",
       "      <td>220</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ning</th>\n",
       "      <td>166</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  occurence_count  document_count\n",
       "lemma                                            \n",
       "seadus                       3004            2988\n",
       "seadu                        2988            2988\n",
       "ja                           1178             918\n",
       "vabariik                      584             338\n",
       "ratifitseerimine              472             469\n",
       "Eesti                         370             330\n",
       "eesti                         363             324\n",
       "seadustik                     274             271\n",
       "konventsioon                  243             229\n",
       "valitsus                      229             121\n",
       "leping                        225             208\n",
       "vaheline                      223             209\n",
       "Euroopa                       220             173\n",
       "euroopa                       220             173\n",
       "ning                          166             159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurence_count</th>\n",
       "      <th>document_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ühisõppus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ühtekuuluvus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ülalpidamine</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üldine</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üldleping</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üleliigne</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üleminekusäte</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ülevõtmine</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ümberkujundamine</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ümberpaigutamine</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üürivaidlus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ˮEuroopa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ˮinimõigus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ˮsisekokkulepe</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ˮüks</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  occurence_count  document_count\n",
       "lemma                                            \n",
       "ühisõppus                       1               1\n",
       "ühtekuuluvus                    1               1\n",
       "ülalpidamine                    1               1\n",
       "üldine                          1               1\n",
       "üldleping                       1               1\n",
       "üleliigne                       1               1\n",
       "üleminekusäte                   1               1\n",
       "ülevõtmine                      1               1\n",
       "ümberkujundamine                1               1\n",
       "ümberpaigutamine                1               1\n",
       "üürivaidlus                     1               1\n",
       "ˮEuroopa                        1               1\n",
       "ˮinimõigus                      1               1\n",
       "ˮsisekokkulepe                  1               1\n",
       "ˮüks                            1               1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemma_counts = result.groupby('lemma').agg(occurence_count=('lemma', len), document_count = ('doc_id', lambda x: len(set(x))))\n",
    "lemma_counts = lemma_counts.sort_values(['occurence_count', 'document_count'], ascending=False)\n",
    "display(lemma_counts.head(15))\n",
    "display(lemma_counts.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffce62-4e98-423a-8c22-f3dc86a171e4",
   "metadata": {},
   "source": [
    "**Observation:** There are clearly non-words inside the lemma list. Lets diagnose what has happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d26ce-877c-41ae-9262-0ebd884b4645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
